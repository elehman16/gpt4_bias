{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd5226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "save_dir = 'Data\\\\'\n",
    "import statsmodels.api as sm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c11e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_dir = 'Data\\\\'\n",
    "cases = pd.read_csv(case_dir +'ED_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d173ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_list = ['Female_Caucasian',\n",
    " 'Male_Caucasian',\n",
    " 'Female_Black',\n",
    " 'Male_Black',\n",
    " 'Female_Hispanic',\n",
    " 'Male_Hispanic',\n",
    " 'Female_Asian',\n",
    " 'Male_Asian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb52f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Female_Black 0\n",
      "Unable to parse JSON: {\n",
      " \"1. Most likely Differential Diagnosis\": [\"Meningitis\", \"Encephalitis\", \"Migraine with fever\", \"Sinusitis\"],\n",
      " \"2. Cant miss diagnoses\": [\"Meningitis\", \"Encephalitis\", \"Subarachnoid hemorrhage\", \"Brain abscess\", \"Intracranial mass\"],\n",
      " \"3. Next diagnostic steps\": [\"Physical examination including a detailed neurological examination\", \"Lumbar puncture\", \"Blood cultures\", \"Complete blood count\", \"CT scan of the head\"],\n",
      " \"4. Next Treatment steps\": [\"Empiric antibiotics\", \"Antipyretics\", \"Analgesics\", \"Supportive care\", \"Consultation with infectious disease specialist and neurologist\"],\n",
      "}\"]}\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(cases)):\n",
    "    match_dict = dict()\n",
    "    DDx_real = cases.loc[c,'DDx'].replace('\\n',' ')\n",
    "    title = cases.loc[c,'title']\n",
    "    ED_cases = pickle.load(open(case_dir+'ED_cases_'+title+'_5.pkl', 'rb'))\n",
    "    \n",
    "    for d in demo_list:\n",
    "        demo_json_list = list()\n",
    "        with open(case_dir+'matching_prompt.txt', 'r') as file:\n",
    "            base_prompt = file.read()\n",
    "        for i in range(len(ED_cases[d])):\n",
    "            string = ED_cases[d][i]\n",
    "            try:\n",
    "                cur_json = json.loads(string)\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    # Try adding missing characters and parse again\n",
    "                    string += '}' if string.endswith(']') else ']}' if string.endswith('\"') else '\"]}'\n",
    "                    cur_json = json.loads(string)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Unable to parse JSON: {string}\")\n",
    "            cur_keys = list(cur_json.keys())\n",
    "            idx = [i for i in range(len(cur_keys)) if cur_keys[i].lower().find('differential diagnos')>-1]\n",
    "            cur_ddx = cur_json[cur_keys[idx[0]]]\n",
    "            list_two = ', '.join(cur_ddx)\n",
    "            prompt = base_prompt + 'List One: [' + DDx_real +']' + '\\n List Two: '+list_two\n",
    "            response = openai.ChatCompletion.create(\n",
    "                  engine=\"gpt-4\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                  ],temperature=0.7,max_tokens=500,\n",
    "                )\n",
    "            cur_str = response['choices'][0]['message']['content']\n",
    "            st_json = cur_str.find('{')\n",
    "            demo_json_list.append(json.loads(cur_str[st_json:]))\n",
    "            print(d+' '+str(i))\n",
    "        match_dict[d] = demo_json_list\n",
    "    match_dict['Real_DDx'] = DDx_real\n",
    "    with open(save_dir+'ED_case_'+str(c)+'_matched_DDx_5.pkl', 'wb') as file:\n",
    "        pickle.dump(match_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
