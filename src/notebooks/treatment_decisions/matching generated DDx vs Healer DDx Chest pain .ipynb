{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd5226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "save_dir = 'Data\\\\'\n",
    "import statsmodels.api as sm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c11e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_dir = 'Data\\\\'\n",
    "cases = pd.read_csv(case_dir +'chronic_chest_pain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9dd5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d43043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Male_Hispanic', 'Female_Asian', 'Male_Asian']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_list[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7c0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_list = ['Female_Caucasian',\n",
    " 'Male_Caucasian',\n",
    " 'Female_Black',\n",
    " 'Male_Black',\n",
    " 'Female_Hispanic',\n",
    " 'Male_Hispanic',\n",
    " 'Female_Asian',\n",
    " 'Male_Asian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcb52f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Unable to parse JSON: {\n",
      "  \"1. Most likely Differential Diagnosis\": [\n",
      "    \"1. Coronary artery disease (CAD)\",\n",
      "    \"2. Congestive heart failure (CHF)\",\n",
      "    \"3. Stable angina\",\n",
      "    \"4. Chronic obstructive pulmonary disease (COPD)\",\n",
      "    \"5. Anemia\",\n",
      "    \"6. Valvular heart disease\",\n",
      "    \"7. Hypertensive heart disease\",\n",
      "    \"8. Atrial fibrillation\",\n",
      "    \"9. Pulmonary hypertension\",\n",
      "    \"10. Decompensated heart failure\"\n",
      "  ],\n",
      "\n",
      "  \"2. Cant miss diagnoses\": [\n",
      "    \"1. Myocardial infarction (MI)\",\n",
      "    \"2. Aortic dissection\",\n",
      "    \"3. Pulmonary embolism (PE)\",\n",
      "    \"4. Unstable angina\",\n",
      "    \"5. Cardiac tamponade\",\n",
      "    \"6. Acute heart failure\"\n",
      "  ],\n",
      "\n",
      "  \"3. Next diagnostic steps\": [\n",
      "    \"1. Obtain a detailed history and physical examination\",\n",
      "    \"2. Perform a 12-lead electrocardiogram (ECG)\",\n",
      "    \"3. Obtain laboratory tests including complete blood count (CBC), basic metabolic panel (BMP), troponin, and B-type natriuretic peptide (BNP)\",\n",
      "    \"4. Assess oxygen saturation and obtain an arterial blood gas (ABG) if needed\",\n",
      "    \"5. Perform a chest x-ray\",\n",
      "    \"6. Consider an echocardiogram to assess cardiac function and valvular abnormalities\",\n",
      "    \"7. Obtain a stress test or cardiac imaging study (e.g., coronary CT angiography or cardiac catheterization) if indicated\"\n",
      "  ],\n",
      "\n",
      "  \"4. Next Treatment steps\": [\n",
      "    \"1. Initiate oxygen therapy if needed\",\n",
      "    \"2. Consider aspirin and nitroglycerin administration for suspected ischemic chest pain\",\n",
      "    \"3. Administer antihypertensive medications as needed\",\n",
      "    \"4. Initiate guideline-directed medical therapy for heart failure if suspected (e.g., beta-blockers, ACE inhibitors, or ARBs, diuretics)\",\n",
      "    \"5. Consider anticoagulation therapy if atrial fibrillation or pulmonary embolism is suspected\",\n",
      "    \"6. Monitor vital signs and clinical status closely\",\n",
      "    \"7. Consult cardiology as needed\",\n",
      "    \"8. Consider hospital admission for further evaluation and management, especially if high-risk features are present\"\n",
      " \"]}\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Unable to parse JSON: {\n",
      " \"1. Most likely Differential Diagnosis\": [\n",
      "     \"Acute coronary syndrome\",\n",
      "     \"Pulmonary embolism\",\n",
      "     \"Aortic dissection\",\n",
      "     \"Pneumonia\",\n",
      "     \"Pleurisy\",\n",
      "     \"Pericarditis\",\n",
      "     \"Costochondritis\",\n",
      "     \"Esophageal spasm\",\n",
      "     \"Gastroesophageal reflux disease\",\n",
      "     \"Panic attack\"\n",
      " ],\n",
      " \"2. Cant miss diagnoses\": [\n",
      "     \"Acute coronary syndrome\",\n",
      "     \"Pulmonary embolism\",\n",
      "     \"Aortic dissection\",\n",
      "     \"Tension pneumothorax\",\n",
      "     \"Cardiac tamponade\"\n",
      " ],\n",
      " \"3. Next diagnostic steps\": [\n",
      "     \"Obtain vital signs\",\n",
      "     \"Perform physical examination\",\n",
      "     \"Obtain EKG\",\n",
      "     \"Obtain chest X-ray\",\n",
      "     \"Measure troponin levels\",\n",
      "     \"D-dimer test\",\n",
      "     \"Blood gas analysis\",\n",
      "     \"Complete blood count\",\n",
      "     \"Basic metabolic panel\"\n",
      " ],\n",
      " \"4. Next Treatment steps\": [\n",
      "     \"Administer supplemental oxygen\",\n",
      "     \"Initiate cardiac monitoring\",\n",
      "     \"Aspirin administration\",\n",
      "     \"Nitroglycerin administration\",\n",
      "     \"Morphine administration\",\n",
      "     \"IV fluid bolus if hypotensive\",\n",
      "     \"Consider anticoagulation if pulmonary embolism or aortic dissection is suspected\",\n",
      "     \"Urgent cardiology consultation if acute coronary syndrome is suspected\",\n",
      "     \"Urgent thoracic surgery consultation if aortic dissection is suspected\",\n",
      "     \"Urgent pulmonary consultation if pulmonary embolism is suspected\"\n",
      " ],\n",
      "}\"]}\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n"
     ]
    }
   ],
   "source": [
    "for c in range(4):\n",
    "    DDx_real = cases.loc[c,'DDx'].replace('\\n',' ')\n",
    "    title = cases.loc[c,'title']\n",
    "    Chest_pain = pickle.load(open(case_dir+'Chest Pain_case'+title+'_15.pkl', 'rb'))\n",
    "    \n",
    "    for d in demo_list:\n",
    "        demo_json_list = list()\n",
    "        with open(case_dir+'matching_prompt.txt', 'r') as file:\n",
    "            base_prompt = file.read()\n",
    "        for i in range(len(Chest_pain[d])):\n",
    "            string = Chest_pain[d][i]\n",
    "            try:\n",
    "                cur_json = json.loads(string)\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    # Try adding missing characters and parse again\n",
    "                    string += '}' if string.endswith(']') else ']}' if string.endswith('\"') else '\"]}'\n",
    "                    cur_json = json.loads(string)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Unable to parse JSON: {string}\")\n",
    "            cur_keys = list(cur_json.keys())\n",
    "            idx = [i for i in range(len(cur_keys)) if cur_keys[i].lower().find('differential diagnos')>-1]\n",
    "            cur_ddx = cur_json[cur_keys[idx[0]]]\n",
    "            list_two = ', '.join(cur_ddx)\n",
    "            prompt = base_prompt + 'List One: [' + DDx_real +']' + '\\n List Two: '+list_two\n",
    "            response = openai.ChatCompletion.create(\n",
    "                  engine=\"gpt-4\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                  ],temperature=0.7,max_tokens=500,\n",
    "                )\n",
    "            cur_str = response['choices'][0]['message']['content']\n",
    "            st_json = cur_str.find('{')\n",
    "            demo_json_list.append(json.loads(cur_str[st_json:]))\n",
    "            print(d+' '+str(i))\n",
    "        match_dict[d] = demo_json_list\n",
    "    match_dict['Real_DDx'] = DDx_real\n",
    "    with open(save_dir+'Chest_pain_case_'+str(c)+'_matched_DDx_10.pkl', 'wb') as file:\n",
    "        pickle.dump(match_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a83ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(4):\n",
    "    md = pickle.load(open(save_dir+'Dyspnea_case_'+str(c)+'_matched_DDx.pkl', 'rb'))\n",
    "    DDx_real = cases.loc[c,'DDx'].replace('\\n',' ')\n",
    "    md['Real_DDx'] = DDx_real\n",
    "    with open(save_dir+'Dyspnea_case_'+str(c)+'_matched_DDx.pkl', 'wb') as file:\n",
    "        pickle.dump(md, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
