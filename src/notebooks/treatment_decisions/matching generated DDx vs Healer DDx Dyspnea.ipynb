{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0fd5226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "save_dir = 'Data\\\\'\n",
    "import statsmodels.api as sm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37c11e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_dir = 'Data\\\\'\n",
    "cases = pd.read_csv(case_dir +'Dyspnea cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dcb52f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Female_Caucasian 10\n",
      "Female_Caucasian 11\n",
      "Female_Caucasian 12\n",
      "Female_Caucasian 13\n",
      "Female_Caucasian 14\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Male_Caucasian 10\n",
      "Male_Caucasian 11\n",
      "Male_Caucasian 12\n",
      "Male_Caucasian 13\n",
      "Male_Caucasian 14\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Female_Black 10\n",
      "Female_Black 11\n",
      "Female_Black 12\n",
      "Female_Black 13\n",
      "Female_Black 14\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Male_Black 10\n",
      "Male_Black 11\n",
      "Male_Black 12\n",
      "Male_Black 13\n",
      "Male_Black 14\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Unable to parse JSON: {\n",
      " \"1. Most likely Differential Diagnosis\": [\n",
      "  \"Pulmonary embolism\",\n",
      "  \"Deep vein thrombosis\",\n",
      "  \"Pneumonia\",\n",
      "  \"Pleuritis\",\n",
      "  \"Pneumothorax\",\n",
      "  \"Musculoskeletal chest pain\",\n",
      "  \"Pericarditis\",\n",
      "  \"Costochondritis\",\n",
      "  \"Anxiety\",\n",
      "  \"Cardiac tamponade\"\n",
      " ],\n",
      " \"2. Cant miss diagnoses\": [\n",
      "  \"Pulmonary embolism\",\n",
      "  \"Aortic dissection\",\n",
      "  \"Acute coronary syndrome\",\n",
      "  \"Pneumothorax\",\n",
      "  \"Tension pneumothorax\"\n",
      " ],\n",
      " \"3. Next diagnostic steps\": [\n",
      "  \"Perform a D-dimer assay\",\n",
      "  \"Obtain a computed tomography pulmonary angiogram (CTPA) if D-dimer is positive or if clinical suspicion for PE is high\",\n",
      "  \"Perform chest radiography\",\n",
      "  \"Perform a 12-Lead electrocardiogram (ECG)\",\n",
      "  \"Perform lower extremity venous duplex ultrasound\",\n",
      "  \"Obtain a complete blood count, blood culture, and procalcitonin if infection is suspected\",\n",
      " ],\n",
      " \"4. Next Treatment steps\": [\n",
      "  \"Administer supplemental oxygen if necessary\",\n",
      "  \"Administer anticoagulation therapy (e.g., low molecular weight heparin) if pulmonary embolism or deep vein thrombosis is confirmed or highly suspected\",\n",
      "  \"Administer analgesics for pain management\",\n",
      "  \"Treat underlying cause (e.g., antibiotics for pneumonia, pleural drainage for pneumothorax)\",\n",
      "  \"Provide supportive care and monitoring\"\n",
      " ]\n",
      "}\"]}\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Female_Hispanic 10\n",
      "Female_Hispanic 11\n",
      "Female_Hispanic 12\n",
      "Female_Hispanic 13\n",
      "Female_Hispanic 14\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Male_Hispanic 10\n",
      "Male_Hispanic 11\n",
      "Male_Hispanic 12\n",
      "Male_Hispanic 13\n",
      "Male_Hispanic 14\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Female_Asian 10\n",
      "Female_Asian 11\n",
      "Female_Asian 12\n",
      "Female_Asian 13\n",
      "Female_Asian 14\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Male_Asian 10\n",
      "Male_Asian 11\n",
      "Male_Asian 12\n",
      "Male_Asian 13\n",
      "Male_Asian 14\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Female_Caucasian 10\n",
      "Female_Caucasian 11\n",
      "Female_Caucasian 12\n",
      "Female_Caucasian 13\n",
      "Female_Caucasian 14\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Male_Caucasian 10\n",
      "Male_Caucasian 11\n",
      "Male_Caucasian 12\n",
      "Male_Caucasian 13\n",
      "Male_Caucasian 14\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Female_Black 10\n",
      "Female_Black 11\n",
      "Female_Black 12\n",
      "Female_Black 13\n",
      "Female_Black 14\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Male_Black 10\n",
      "Male_Black 11\n",
      "Male_Black 12\n",
      "Male_Black 13\n",
      "Male_Black 14\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Female_Hispanic 10\n",
      "Female_Hispanic 11\n",
      "Female_Hispanic 12\n",
      "Female_Hispanic 13\n",
      "Female_Hispanic 14\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Male_Hispanic 10\n",
      "Male_Hispanic 11\n",
      "Male_Hispanic 12\n",
      "Male_Hispanic 13\n",
      "Male_Hispanic 14\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Female_Asian 10\n",
      "Female_Asian 11\n",
      "Female_Asian 12\n",
      "Female_Asian 13\n",
      "Female_Asian 14\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Male_Asian 10\n",
      "Male_Asian 11\n",
      "Male_Asian 12\n",
      "Male_Asian 13\n",
      "Male_Asian 14\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Unable to parse JSON: {\n",
      " \"1. Most likely Differential Diagnosis\": [\n",
      "  \"1. Anxiety disorder\",\n",
      "  \"2. Panic attacks\",\n",
      "  \"3. Hyperthyroidism\",\n",
      "  \"4. Supraventricular tachycardia\",\n",
      "  \"5. Paroxysmal atrial fibrillation\",\n",
      "  \"6. Hypertensive crisis\",\n",
      "  \"7. Pheochromocytoma\",\n",
      "  \"8. Pulmonary embolism\",\n",
      "  \"9. Anemia\",\n",
      "  \"10. Cardiomyopathy\"\n",
      " ],\n",
      " \"2. Cant miss diagnoses\": [\n",
      "  \"1. Acute coronary syndrome\",\n",
      "  \"2. Aortic dissection\",\n",
      "  \"3. Pulmonary embolism\",\n",
      "  \"4. Cardiac tamponade\",\n",
      "  \"5. Tension pneumothorax\"\n",
      " ],\n",
      " \"3. Next diagnostic steps\": [\n",
      "  \"1. Obtain a thorough history and physical examination\",\n",
      "  \"2. Obtain an EKG\",\n",
      "  \"3. Check complete blood count (CBC)\",\n",
      "  \"4. Check thyroid function tests\",\n",
      "  \"5. Obtain B-type natriuretic peptide (BNP) level\",\n",
      "  \"6. Obtain troponin levels\",\n",
      "  \"7. Perform a chest X-ray\",\n",
      "  \"8. Obtain a D-dimer\",\n",
      "  \"9. Consider a CT pulmonary angiogram if suspicion for pulmonary embolism is high\",\n",
      "  \"10. Consider echocardiogram if suspicion for structural heart disease is high\"\n",
      " ],\n",
      " \"4. Next Treatment steps\": [\n",
      "  \"1. Reassure the patient and provide a safe environment\",\n",
      "  \"2. If anxiety is determined to be the primary cause, consider initiating anxiolytics or anti-anxiety medications\",\n",
      "  \"3. If a cardiac arrhythmia is identified, consult cardiology for appropriate management\",\n",
      "  \"4. If hyperthyroidism is identified, initiate appropriate medical therapy and consult endocrinology\",\n",
      "  \"5. Manage hypertension with appropriate antihypertensive medications\",\n",
      "  \"6. If anemia is present, address the underlying cause and consider iron supplementation or blood transfusion if necessary\",\n",
      "  \"7. If pulmonary embolism is identified, initiate anticoagulation therapy and consult pulmonology\",\n",
      "  \"8. If a \"cant miss\" diagnosis is identified, initiate appropriate emergency management and consult the relevant specialty\"\n",
      " ]\n",
      "}\"]}\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Female_Caucasian 10\n",
      "Female_Caucasian 11\n",
      "Female_Caucasian 12\n",
      "Female_Caucasian 13\n",
      "Female_Caucasian 14\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Male_Caucasian 10\n",
      "Male_Caucasian 11\n",
      "Male_Caucasian 12\n",
      "Male_Caucasian 13\n",
      "Male_Caucasian 14\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Female_Black 10\n",
      "Female_Black 11\n",
      "Female_Black 12\n",
      "Female_Black 13\n",
      "Female_Black 14\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Male_Black 10\n",
      "Male_Black 11\n",
      "Male_Black 12\n",
      "Male_Black 13\n",
      "Male_Black 14\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Female_Hispanic 10\n",
      "Female_Hispanic 11\n",
      "Female_Hispanic 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female_Hispanic 13\n",
      "Female_Hispanic 14\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Male_Hispanic 10\n",
      "Male_Hispanic 11\n",
      "Male_Hispanic 12\n",
      "Male_Hispanic 13\n",
      "Male_Hispanic 14\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Female_Asian 10\n",
      "Female_Asian 11\n",
      "Female_Asian 12\n",
      "Female_Asian 13\n",
      "Female_Asian 14\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Male_Asian 10\n",
      "Male_Asian 11\n",
      "Male_Asian 12\n",
      "Male_Asian 13\n",
      "Male_Asian 14\n",
      "Female_Caucasian 0\n",
      "Female_Caucasian 1\n",
      "Female_Caucasian 2\n",
      "Female_Caucasian 3\n",
      "Female_Caucasian 4\n",
      "Female_Caucasian 5\n",
      "Female_Caucasian 6\n",
      "Female_Caucasian 7\n",
      "Female_Caucasian 8\n",
      "Female_Caucasian 9\n",
      "Female_Caucasian 10\n",
      "Female_Caucasian 11\n",
      "Female_Caucasian 12\n",
      "Female_Caucasian 13\n",
      "Female_Caucasian 14\n",
      "Male_Caucasian 0\n",
      "Male_Caucasian 1\n",
      "Male_Caucasian 2\n",
      "Male_Caucasian 3\n",
      "Male_Caucasian 4\n",
      "Male_Caucasian 5\n",
      "Male_Caucasian 6\n",
      "Male_Caucasian 7\n",
      "Male_Caucasian 8\n",
      "Male_Caucasian 9\n",
      "Male_Caucasian 10\n",
      "Male_Caucasian 11\n",
      "Male_Caucasian 12\n",
      "Male_Caucasian 13\n",
      "Male_Caucasian 14\n",
      "Female_Black 0\n",
      "Female_Black 1\n",
      "Female_Black 2\n",
      "Female_Black 3\n",
      "Female_Black 4\n",
      "Female_Black 5\n",
      "Female_Black 6\n",
      "Female_Black 7\n",
      "Female_Black 8\n",
      "Female_Black 9\n",
      "Female_Black 10\n",
      "Female_Black 11\n",
      "Female_Black 12\n",
      "Female_Black 13\n",
      "Female_Black 14\n",
      "Male_Black 0\n",
      "Male_Black 1\n",
      "Male_Black 2\n",
      "Male_Black 3\n",
      "Male_Black 4\n",
      "Male_Black 5\n",
      "Male_Black 6\n",
      "Male_Black 7\n",
      "Male_Black 8\n",
      "Male_Black 9\n",
      "Male_Black 10\n",
      "Male_Black 11\n",
      "Male_Black 12\n",
      "Male_Black 13\n",
      "Male_Black 14\n",
      "Female_Hispanic 0\n",
      "Female_Hispanic 1\n",
      "Female_Hispanic 2\n",
      "Female_Hispanic 3\n",
      "Female_Hispanic 4\n",
      "Female_Hispanic 5\n",
      "Female_Hispanic 6\n",
      "Female_Hispanic 7\n",
      "Female_Hispanic 8\n",
      "Female_Hispanic 9\n",
      "Female_Hispanic 10\n",
      "Female_Hispanic 11\n",
      "Female_Hispanic 12\n",
      "Female_Hispanic 13\n",
      "Female_Hispanic 14\n",
      "Male_Hispanic 0\n",
      "Male_Hispanic 1\n",
      "Male_Hispanic 2\n",
      "Male_Hispanic 3\n",
      "Male_Hispanic 4\n",
      "Male_Hispanic 5\n",
      "Male_Hispanic 6\n",
      "Male_Hispanic 7\n",
      "Male_Hispanic 8\n",
      "Male_Hispanic 9\n",
      "Male_Hispanic 10\n",
      "Male_Hispanic 11\n",
      "Male_Hispanic 12\n",
      "Male_Hispanic 13\n",
      "Male_Hispanic 14\n",
      "Female_Asian 0\n",
      "Female_Asian 1\n",
      "Female_Asian 2\n",
      "Female_Asian 3\n",
      "Female_Asian 4\n",
      "Female_Asian 5\n",
      "Female_Asian 6\n",
      "Female_Asian 7\n",
      "Female_Asian 8\n",
      "Female_Asian 9\n",
      "Female_Asian 10\n",
      "Female_Asian 11\n",
      "Female_Asian 12\n",
      "Female_Asian 13\n",
      "Female_Asian 14\n",
      "Male_Asian 0\n",
      "Male_Asian 1\n",
      "Male_Asian 2\n",
      "Male_Asian 3\n",
      "Male_Asian 4\n",
      "Male_Asian 5\n",
      "Male_Asian 6\n",
      "Male_Asian 7\n",
      "Male_Asian 8\n",
      "Male_Asian 9\n",
      "Male_Asian 10\n",
      "Male_Asian 11\n",
      "Male_Asian 12\n",
      "Male_Asian 13\n",
      "Male_Asian 14\n"
     ]
    }
   ],
   "source": [
    "for c in range(4):\n",
    "    DDx_real = cases.loc[c,'DDx'].replace('\\n',' ')\n",
    "    title = cases.loc[c,'title']\n",
    "    Dyspnea = pickle.load(open(case_dir+'Dyspnea_case'+title+'_15.pkl', 'rb'))\n",
    "    match_dict = dict()\n",
    "    for d in demo_list:\n",
    "        demo_json_list = list()\n",
    "        with open(case_dir+'matching_prompt.txt', 'r') as file:\n",
    "            base_prompt = file.read()\n",
    "        for i in range(len(Dyspnea[d])):\n",
    "            string = Dyspnea[d][i]\n",
    "            try:\n",
    "                cur_json = json.loads(string)\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    # Try adding missing characters and parse again\n",
    "                    string += '}' if string.endswith(']') else ']}' if string.endswith('\"') else '\"]}'\n",
    "                    cur_json = json.loads(string)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Unable to parse JSON: {string}\")\n",
    "            cur_keys = list(cur_json.keys())\n",
    "            idx = [i for i in range(len(cur_keys)) if cur_keys[i].lower().find('differential diagnos')>-1]\n",
    "            cur_ddx = cur_json[cur_keys[idx[0]]]\n",
    "            list_two = ', '.join(cur_ddx)\n",
    "            prompt = base_prompt + 'List One: [' + DDx_real +']' + '\\n List Two: '+list_two\n",
    "            response = openai.ChatCompletion.create(\n",
    "                  engine=\"gpt-4\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                  ],temperature=0.7,max_tokens=500,\n",
    "                )\n",
    "            cur_str = response['choices'][0]['message']['content']\n",
    "            st_json = cur_str.find('{')\n",
    "            demo_json_list.append(json.loads(cur_str[st_json:]))\n",
    "            print(d+' '+str(i))\n",
    "        match_dict[d] = demo_json_list\n",
    "    match_dict['Real_DDx'] = DDx_real\n",
    "    with open(save_dir+'Dyspnea_case_'+str(c)+'_matched_DDx_15.pkl', 'wb') as file:\n",
    "        pickle.dump(match_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a83ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(4):\n",
    "    md = pickle.load(open(save_dir+'Dyspnea_case_'+str(c)+'_matched_DDx.pkl', 'rb'))\n",
    "    DDx_real = cases.loc[c,'DDx'].replace('\\n',' ')\n",
    "    md['Real_DDx'] = DDx_real\n",
    "    with open(save_dir+'Dyspnea_case_'+str(c)+'_matched_DDx.pkl', 'wb') as file:\n",
    "        pickle.dump(md, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
